{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Pytorch and JAX\n",
    "\n",
    "In this post, we hope to concisely introduce two prominent frameworks for deep learning: Pytorch and JAX. \n",
    "\n",
    "We also hoped to cover Tensorflow. But for reasons unclear to us, we were unable to install Tensorflow both with Python 3.12 and Python 3.11. Given the simultaneous development of Tensorflow and JAX within Google, and the recent popularity of JAX, I wouldn't be surprised if Tensorflow is heading towards deprecation in the future. For completeness, it is worth noting that Tensorflow is the oldest among the three, being first introduced in 2011.\n",
    "\n",
    "Pytorch was first introduced in 2016 by Adam Paszke and Soumith Chintala along with others at FAIR [[1](#ref-1)]. Some features that made Pytorch stand out over Tensorflow when it was introduced are: dynamic computational graph, pythonic nature, and extensive ecosystem - notably torchvision, torchaudio, and torchtext.\n",
    "\n",
    "JAX (\"just after execution\") was first introduced in 2018 by Roy Frostig, Matthew James Johnson, and Chris Leary at Google Brain [[2](#ref-2)]. Some unique features of JAX include: jit compilation (\"just in time compilation\"), XLA (\"accelerated linear algebra\"), autovectorization & large data parallelism (via `vmap` and `pmap` respectively). JAX is known for its computational efficiency on hardware accelerators like GPUs and TPUs. \n",
    "\n",
    "What both Pytorch and JAX have in common is automatic differentiation (`autograd` in pytorch, and just `grad` in JAX). The execution speed however is faster in JAX since it benefits from autovectorization and jit compilation abilities mentioned earlier. On the other hand, what makes Pytorch and JAX fundamentally different as frameworks is the programming paradigm they use: Pytorch is object-oriented, while JAX is functional.\n",
    "\n",
    "Let us look at some examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural net architecture class (784+128+10 neurons, where the second and third layer are fully connected)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "net = Net()\n",
    "# Load dataset (FashionMNIST from torchvision)\n",
    "training_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "trainloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# Choose loss function and optimizer (cross-entropy loss, stochastic gradient descent)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(2):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data               # get data stored as [inputs, labels] in trainloader\n",
    "        optimizer.zero_grad()               # zero the parameter gradients\n",
    "        outputs = net(inputs)               # forward pass\n",
    "        loss = criterion(outputs, labels)   # compute loss function\n",
    "        loss.backward()                     # backward pass\n",
    "        optimizer.step()                    # update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No need to track gradients for evaluation\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Calculate the accuracy on the test dataset\n",
    "accuracy = evaluate_model(net, test_loader)\n",
    "print(f'Accuracy of the model on the test images: {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've trained a simple neural net with two fully connected layers (784+128+10 neurons) on FashionMNIST (clothes classification dataset in torchvision), with a seemingly lacklustre accuracy of 57.59 percent. In any case, we would like some visualization of the trained weights. For this, we will try two methods: matplotlib and torchviz. Let's first look at matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weights that connect to first fully connected layer 'fc1' (128x784 matrix)\n",
    "weights = net.fc1.weight.data.numpy()\n",
    "# Present weights matrix as 128 images of 28x28 resolution\n",
    "# num_x = int(np.ceil(np.sqrt(len(weights))))  \n",
    "# num_y = num_x                                \n",
    "fig, axes = plt.subplots(11, 12, figsize=(15, 15)) \n",
    "for i, ax in enumerate(axes.flat):  \n",
    "    if i < len(weights):    \n",
    "        ax.imshow(weights[i].reshape(28, 28), cmap='gray')  \n",
    "    ax.axis('off')\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see above is a matplotlib visualization of the trained weight matrix for the first fully connected layer (with 128 neurons, each getting 784 = 28*28 weights, visualized as grayscale images). Let us now try torchviz, a network visualization tool for pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy input tensor that matches the input shape of the network\n",
    "dummy_input = torch.randn(1, 784)\n",
    "# Perform a forward pass to get the output\n",
    "output = net(dummy_input)\n",
    "# Visualize the computational graph\n",
    "graph = make_dot(output.mean(), params=dict(net.named_parameters()))\n",
    "graph.render('network_graph', format='png')  # This will save the graph as a PNG image\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we get is a torchviz visualization of the neural net flow : two fully connected layers fc1 and fc2, fc1 has 128 neurons each with 784 weights, and fc2 has 10 neurons each with 128 weights. each input is a 28*28 image.\n",
    "\n",
    "Let us now try to implement the same example in JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "\n",
    "# Define neural net architecture class\n",
    "class SimpleNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = jnp.reshape(x, (x.shape[0], -1))  # Flatten input\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x\n",
    "# Define functions to embed the train & test data into numpy arrays\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple, list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "def prepare_dataloader(dataset, *args, **kwargs):\n",
    "    return DataLoader(dataset, collate_fn=numpy_collate, *args, **kwargs)\n",
    "# Load train & test data (FashionMNIST from torchvision again)\n",
    "training_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "trainloader = prepare_dataloader(training_data, batch_size=64, shuffle=True)\n",
    "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "testloader = prepare_dataloader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define cross-entropy loss\n",
    "def cross_entropy_loss(*, logits, labels):\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(labels_onehot * jax.nn.log_softmax(logits), axis=-1))\n",
    "# Define update step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    inputs, labels = batch\n",
    "    inputs = jnp.array(inputs).reshape(inputs.shape[0], -1)\n",
    "    labels = jnp.array(labels)\n",
    "    def loss_fn(params):\n",
    "        logits = SimpleNN().apply({'params': params}, inputs)\n",
    "        loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss, logits\n",
    "    \n",
    "# Train the network\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "model = SimpleNN()\n",
    "params = model.init(init_rng, jnp.ones([1, 28 * 28]))['params']\n",
    "\n",
    "tx = optax.sgd(learning_rate=0.001, momentum=0.9)   # Stochastic Gradient Descent optimizer provided by optax\n",
    "state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "for epoch in range(2):\n",
    "    for batch in trainloader:\n",
    "        state, loss, logits = train_step(state, batch)\n",
    "\n",
    "# Evaluate the network's performance\n",
    "def accuracy(logits, labels):\n",
    "    return jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "    inputs, labels = batch\n",
    "    inputs = jnp.array(inputs).reshape(inputs.shape[0], -1)\n",
    "    labels = jnp.array(labels)\n",
    "    logits = model.apply({'params': params}, inputs)\n",
    "    return accuracy(logits, labels)\n",
    "accuracies = []\n",
    "for batch in testloader:\n",
    "    accuracies.append(eval_step(state.params, batch))\n",
    "print('Test set accuracy:', np.mean(accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, while Pytorch trained with a poor 57.6 percent test accuracy, JAX got 79.7 percent test accuracy. This is despite using the same optimizer (SGD with learning rate 0.001 and momentum 0.9) and the same loss function (cross-entropy). So either the test dataset is created somewhat differently (or) JAX is superior in accuracy to Pytorch. I don't know if the latter is true in general, but I guess we'll learn more as I continue experimenting in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and visualize like before. This time we can do exactly what we did with matplotlib earlier, however we cannot use torchviz. In my exploration, I didn't come across a simple equivialent of torchviz in JAX. Leaving that aside, let's go ahead and visualize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = state.params['Dense_0']['kernel']\n",
    "# Transpose the weights to match the input shape for visualization\n",
    "weights = weights.T\n",
    "\n",
    "# Reshape and plot the weights\n",
    "fig, axes = plt.subplots(11, 12, figsize=(15, 15))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < weights.shape[0]:  # Check to avoid index error\n",
    "        weight = weights[i].reshape(28, 28)  # Reshape the weight to 28x28\n",
    "        ax.imshow(weight, cmap='gray')\n",
    "    ax.axis('off')\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. While there isn't too much we learn at this low a resolution, if we carefully compare the structure of the Pytorch and JAX weights, we see that JAX has more fine-grained variation in the trained weights, which from a distance looks more random than the pytorch weights. But clearly they've learnt different weights, and JAX's superior accuracy might be stemming from its ability to pick up more fine-grained spatial variations in the input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References  \n",
    "[1] <a id=\"ref-1\"></a> [https://proceedings.neurips.cc/paper_files/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf)  \n",
    "[2] <a id=\"ref-2\"></a> [https://mlsys.org/Conferences/doc/2018/146.pdf](https://mlsys.org/Conferences/doc/2018/146.pdf)  \n",
    "<!-- use two extra spaces at end of each line for line break -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
